{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search: vector search, step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import azure.identity\n",
    "import dotenv\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import openai\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, SimpleField, SearchableField, SearchFieldDataType\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_api_key = \"\"\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_SEARCH_SERVICE = \"genai-azureaisearch\"\n",
    "search_endpoint = f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\"\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=AzureKeyCredential(search_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to generate embeddings using Azure OpenAI\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(input=text, engine=\"text-embedding-ada-002\")\n",
    "    return response['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search a tiny index\n",
    "\n",
    "### Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SimpleField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchProfile,\n",
    ")\n",
    "\n",
    "AZURE_SEARCH_TINY_INDEX = \"teeenytinyindex\"\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=AZURE_SEARCH_TINY_INDEX, \n",
    "    fields=[\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchField(name=\"embedding\", \n",
    "                    type=SearchFieldDataType.Collection(SearchFieldDataType.Single), \n",
    "                    searchable=True, \n",
    "                    vector_search_dimensions=3,\n",
    "                    vector_search_profile_name=\"embedding_profile\")\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        algorithms=[HnswAlgorithmConfiguration( # Hierachical Navigable Small World, IVF\n",
    "                            name=\"hnsw_config\",\n",
    "                            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "                            parameters=HnswParameters(metric=\"cosine\"),\n",
    "                        )],\n",
    "        profiles=[VectorSearchProfile(name=\"embedding_profile\", algorithm_configuration_name=\"hnsw_config\")]\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-search-documents in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (11.5.2)\n",
      "Collecting azure-search-documents\n",
      "  Downloading azure_search_documents-11.6.0b11-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: azure-core>=1.28.0 in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (from azure-search-documents) (1.34.0)\n",
      "Requirement already satisfied: azure-common>=1.1 in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (from azure-search-documents) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (from azure-search-documents) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (from azure-search-documents) (4.13.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (from azure-core>=1.28.0->azure-search-documents) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (from azure-core>=1.28.0->azure-search-documents) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-search-documents) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-search-documents) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-search-documents) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cheekish\\desktop\\gen-ai\\myenv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-search-documents) (2025.4.26)\n",
      "Downloading azure_search_documents-11.6.0b11-py3-none-any.whl (338 kB)\n",
      "Installing collected packages: azure-search-documents\n",
      "  Attempting uninstall: azure-search-documents\n",
      "    Found existing installation: azure-search-documents 11.5.2\n",
      "    Uninstalling azure-search-documents-11.5.2:\n",
      "      Successfully uninstalled azure-search-documents-11.5.2\n",
      "Successfully installed azure-search-documents-11.6.0b11\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade azure-search-documents --pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, SimpleField, SearchField,\n",
    "    SearchFieldDataType, VectorSearch, VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration, VectorSearchAlgorithmKind, HnswParameters\n",
    ")\n",
    "\n",
    "AZURE_SEARCH_TINY_INDEX = \"teeenytinyindex\"\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=AZURE_SEARCH_TINY_INDEX,\n",
    "    fields=[\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchField(\n",
    "            name=\"embedding\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=3,\n",
    "            vector_search_profile_name=\"embedding_profile\"\n",
    "        )\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"hnsw_config\",\n",
    "                kind=VectorSearchAlgorithmKind.HNSW,\n",
    "                parameters=HnswParameters(metric=\"cosine\")\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"embedding_profile\",\n",
    "                algorithm_configuration_name=\"hnsw_config\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert a few documents with tiny vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload result: [<azure.search.documents._generated.models._models_py3.IndexingResult object at 0x000001BE2E3D4C10>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x000001BE2C691310>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x000001BE2C692610>]\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=AZURE_SEARCH_TINY_INDEX, credential=AzureKeyCredential(search_api_key))\n",
    "\n",
    "# Ensure the documents conform to the schema defined in the index\n",
    "documents = [\n",
    "    {\"id\": \"1\"},\n",
    "    {\"id\": \"2\"},\n",
    "    {\"id\": \"3\"}\n",
    "]\n",
    "\n",
    "# Upload the documents to the index\n",
    "# Ensure the embedding field is correctly formatted as a list of floats\n",
    "\n",
    "result = search_client.upload_documents(documents=documents)\n",
    "print(f\"Upload result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search using vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HybridCountAndFacetMode' from 'azure.search.documents._generated.models' (c:\\Users\\cheekish\\Desktop\\Gen-AI\\myenv\\Lib\\site-packages\\azure\\search\\documents\\_generated\\models\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msearch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocuments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorizedQuery\n\u001b[32m      3\u001b[39m r = search_client.search(search_text=\u001b[38;5;28;01mNone\u001b[39;00m, vector_queries=[\n\u001b[32m      4\u001b[39m     VectorizedQuery(vector=[-\u001b[32m2\u001b[39m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m], k_nearest_neighbors=\u001b[32m3\u001b[39m, fields=\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m)])\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m r:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheekish\\Desktop\\Gen-AI\\myenv\\Lib\\site-packages\\azure\\search\\documents\\models\\__init__.py:27\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Copyright (c) Microsoft Corporation. All rights reserved.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_generated\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     AutocompleteMode,\n\u001b[32m     29\u001b[39m     HybridCountAndFacetMode,\n\u001b[32m     30\u001b[39m     HybridSearch,\n\u001b[32m     31\u001b[39m     IndexAction,\n\u001b[32m     32\u001b[39m     IndexingResult,\n\u001b[32m     33\u001b[39m     QueryAnswerResult,\n\u001b[32m     34\u001b[39m     QueryAnswerType,\n\u001b[32m     35\u001b[39m     QueryCaptionResult,\n\u001b[32m     36\u001b[39m     QueryCaptionType,\n\u001b[32m     37\u001b[39m     QueryDebugMode,\n\u001b[32m     38\u001b[39m     QueryLanguage,\n\u001b[32m     39\u001b[39m     QueryRewritesType,\n\u001b[32m     40\u001b[39m     QuerySpellerType,\n\u001b[32m     41\u001b[39m     QueryType,\n\u001b[32m     42\u001b[39m     ScoringStatistics,\n\u001b[32m     43\u001b[39m     SearchMode,\n\u001b[32m     44\u001b[39m     SearchScoreThreshold,\n\u001b[32m     45\u001b[39m     SemanticErrorMode,\n\u001b[32m     46\u001b[39m     SemanticErrorReason,\n\u001b[32m     47\u001b[39m     SemanticSearchResultsType,\n\u001b[32m     48\u001b[39m     VectorFilterMode,\n\u001b[32m     49\u001b[39m     VectorSimilarityThreshold,\n\u001b[32m     50\u001b[39m     VectorThreshold,\n\u001b[32m     51\u001b[39m     VectorThresholdKind,\n\u001b[32m     52\u001b[39m     VectorizableImageBinaryQuery,\n\u001b[32m     53\u001b[39m     VectorizableImageUrlQuery,\n\u001b[32m     54\u001b[39m     VectorizedQuery,\n\u001b[32m     55\u001b[39m     VectorizableTextQuery,\n\u001b[32m     56\u001b[39m     VectorQuery,\n\u001b[32m     57\u001b[39m )\n\u001b[32m     60\u001b[39m __all__ = (\n\u001b[32m     61\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAutocompleteMode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     62\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mHybridCountAndFacetMode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mVectorQuery\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     90\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'HybridCountAndFacetMode' from 'azure.search.documents._generated.models' (c:\\Users\\cheekish\\Desktop\\Gen-AI\\myenv\\Lib\\site-packages\\azure\\search\\documents\\_generated\\models\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "r = search_client.search(search_text=None, vector_queries=[\n",
    "    VectorizedQuery(vector=[-2, -1, -1], k_nearest_neighbors=3, fields=\"embedding\")])\n",
    "for doc in r:\n",
    "    print(f\"id: {doc['id']}, score: {doc['@search.score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search a larger index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.identity\n",
    "import dotenv\n",
    "import openai\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Initialize Azure search variables\n",
    "AZURE_SEARCH_SERVICE = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_ENDPOINT = f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\"\n",
    "\n",
    "# Set up OpenAI client based on environment variables\n",
    "dotenv.load_dotenv()\n",
    "AZURE_OPENAI_SERVICE = os.getenv(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_ADA_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_ADA_DEPLOYMENT\")\n",
    "\n",
    "token_provider = azure.identity.get_bearer_token_provider(azure_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "openai_client = openai.AzureOpenAI(\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\",\n",
    "    azure_ad_token_provider=token_provider)\n",
    "\n",
    "def get_embedding(text):\n",
    "    get_embeddings_response = openai_client.embeddings.create(model=AZURE_OPENAI_ADA_DEPLOYMENT, input=text)\n",
    "    return get_embeddings_response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.80732\tContent: Some of the lessons covered under PerksPlus include: 路 Skiing and snowboarding lessons 路 Scuba diving lessons 路 Surfing lessons 路 Horseback riding le\n",
      "Score: 0.79299\tContent: PerksPlus is not only designed to support employees' physical health, but also their mental health. Regular exercise has been shown to reduce stress,\n",
      "Score: 0.79254\tContent: Under the Northwind Health Plus plan, habilitation services are covered up to a certain dollar amount and number of visits. This amount and the numbe\n",
      "Score: 0.78812\tContent: It is important to understand which type of therapy is best suited for the individual's needs and goals. It is also important to note that habilitati\n",
      "Score: 0.78661\tContent: Occupational Therapy Occupational therapy helps individuals develop, maintain, or restore skills for daily living and work. It can help individuals w\n"
     ]
    }
   ],
   "source": [
    "AZURE_SEARCH_FULL_INDEX = \"gptkbindex\"\n",
    "search_client = SearchClient(AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_FULL_INDEX, credential=azure_credential)\n",
    "\n",
    "search_query = \"learning about underwater activities\"\n",
    "search_vector = get_embedding(search_query)\n",
    "r = search_client.search(search_text=None, top=5, vector_queries=[\n",
    "    VectorizedQuery(vector=search_vector, k_nearest_neighbors=5, fields=\"embedding\")])\n",
    "for doc in r:\n",
    "    content = doc[\"content\"].replace(\"\\n\", \" \")[:150]\n",
    "    print(f\"Score: {doc['@search.score']:.5f}\\tContent:{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
